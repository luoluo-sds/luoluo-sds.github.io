<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html> 
<head>
   <title> Luo Luo (Fudan) </title>
   <link rel=stylesheet href="style.css" type="text/css">
   <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>

<body> 
	<h1>Luo Luo </h1>
	Email: luoluo (AT) fudan (DOT) edu (DOT) cn<br>
	<br>
	My research interests include machine learning, optimization and linear algebra.
	<hr>

	<h3>Teaching </h3>
	<ul><li> Optimization Theory (2023, 2024, <a href="/teaching/data620020.html">2025</a>) </li></ul>
	<ul><li> Multivariate Statistical Analysis (2022, 2023, <a href="/teaching/data130044.html">2024</a>) </li></ul>
	<ul><li> Multivariate Statistics (2022)  </li></ul>
	<hr>
	
	<h3> Preprints </h3>

	<ul><li> Lesi Chen, Chengchang Liu, <b>Luo Luo</b>, Jingzhao Zhang. <br>
	Computationally Faster Newton Methods by Lazy Evaluations. <br>
	arXiv preprint:2501.17488, 2025. <br>
	[<a href="https://arxiv.org/pdf/2501.17488">pdf</a>] 
	</li></ul>
	
	<ul><li> Zhiling Zhou, Zhuanghua Liu, Chengchang Liu, <b>Luo Luo</b>. <br>
	Incremental Gauss–Newton Methods with Superlinear Convergence Rates. <br>
	arXiv preprint:2407.03195, 2024. <br>
	[<a href="https://arxiv.org/pdf/2407.03195">pdf</a>] 
	</li></ul>
	
	<ul><li> Chengchang Liu, Cheng Chen, <b>Luo Luo</b>. <br>
	Symmetric Rank-k Methods. <br>
	arXiv preprint:2303.16188, 2023. <br>
	[<a href="https://arxiv.org/pdf/2303.16188.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Chengchang Liu, <b>Luo Luo</b>. <br>
	Regularized Newton Methods for Monotone Variational Inequalities with H&#246;lder Continuous Jacobians. <br>
	arXiv preprint:2212.07824, 2022. <br>
	[<a href="https://arxiv.org/pdf/2212.07824.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> <b>Luo Luo</b>, Yunyan Bai, Lesi Chen, Yuxing Liu, Haishan Ye. <br>
	On the Complexity of Decentralized Smooth Nonconvex Finite-Sum Optimization. <br>
	arXiv preprint:2210.13931, 2022. <br>
	[<a href="https://arxiv.org/pdf/2210.13931.pdf">pdf</a>] 
	</li></ul>
	
	<h3> Publications </h3>

	<ul><li> Lesi Chen, Chengchang Liu, <b>Luo Luo</b>, Jingzhao Zhang. <br>
	Solving Convex-Concave Problems with \(\tilde{\mathcal{O}}(\epsilon^{-4/7})\) Second-Order Oracle Complexity. <br>
	Conference on Learning Theory (COLT), 2025. <br> 
	<b> <font color="#FF0000"> Best Student Paper Award </font> </b> <br>
	</li></ul>
	
	<ul><li> Kunjie Ren, <b>Luo Luo</b>*. <br>
	A Parameter-Free and Near-Optimal Zeroth-Order Algorithm for Stochastic Convex Optimization. <br>
	International Conference on Machine Learning (ICML), 2025. <br>
	[<a href="https://arxiv.org/pdf/2502.05600">pdf</a>] 
	</li></ul>

	<ul><li> Chengchang Liu, <b>Luo Luo</b>*, John C.S. Lui. <br>
	An Enhanced Levenberg–Marquardt Method via Gram Reduction. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2025. <br>
	[<a href="https://doi.org/10.1609/aaai.v39i18.34066">pdf</a>] 
	</li></ul>	

	<ul><li> Lesi Chen, <b> Luo Luo</b>*. <br>
	Near-Optimal Algorithms for Making the Gradient Small in Stochastic Minimax Optimization. <br>
	Journal of Machine Learning Research (JMLR), 25(387):1−44, 2024. <br>
	[<a href="https://jmlr.org/papers/volume25/22-1126/22-1126.pdf">pdf</a>]
	</li></ul>
	
	<ul><li> Qihao Zhou, Haishan Ye, <b>Luo Luo</b>*. <br>
	Near-Optimal Distributed Minimax Optimization under the Second-Order Similarity. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2024. <br>
	[<a href="https://openreview.net/pdf?id=pgUQFIJ6BE">pdf</a>] 
	</li></ul>

	<ul><li> Zhuanghua Liu, <b>Luo Luo</b>*, Bryan Kian Hsiang Low. <br> 
	Gradient-Free Methods for Nonconvex Nonsmooth Stochastic Compositional Optimization. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2024. <br>
	[<a href="https://openreview.net/pdf?id=UVAq3uJ0gc">pdf</a>]		
	</li></ul>
	
	<ul><li> Shihong Ding, Long Yang, <b>Luo Luo</b>, Cong Fang. <br>
	Optimizing over Multiple Distributions under Generalized Quasar-Convexity Condition. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2024. <br>
	[<a href="https://openreview.net/pdf?id=lOV9kSX3Uo">pdf</a>] 
	</li></ul>

	<ul><li> Zhuanghua Liu, Cheng Chen, <b>Luo Luo</b>*, Bryan Kian Hsiang Low. <br>
	Zeroth-Order Methods for Constrained Nonconvex Nonsmooth Stochastic Optimization. <br>
	International Conference on Machine Learning (ICML), 2024.  <a href="https://icml.cc/virtual/2024/oral/35528" style="text-decoration:none"> <b> <font color="#FF0000"> Oral </font> </b> <a> <br>
	[<a href="https://openreview.net/pdf?id=PxHmxoFOgI">pdf</a>]	
	</li></ul>		

	<ul><li> Yunyan Bai, Yuxing Liu, <b>Luo Luo</b>*. <br>
	On the Complexity of Finite-Sum Smooth Optimization under the Polyak–&#321;ojasiewicz Condition. <br>
	International Conference on Machine Learning (ICML), 2024. <a href="https://icml.cc/virtual/2024/poster/33207" style="text-decoration:none"> <b> <font color="#FF0000"> Spotlight </font> </b> <a> <br>
	[<a href="https://openreview.net/pdf?id=leJGQCron2">pdf</a>] 
	</li></ul>	

	<ul><li> Yuxing Liu, Lesi Chen, <b>Luo Luo</b>*. <br>
	Decentralized Convex Finite-Sum Optimization with Better Dependence on Condition Numbers. <br>
	International Conference on Machine Learning (ICML), 2024. <br>
	[<a href="https://openreview.net/pdf?id=LLdeUPOUXk">pdf</a>]	
	</li></ul>	

	<ul><li> Lesi Chen, Haishan Ye, <b>Luo Luo</b>*. <br>
	An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization. <br>
	International Conference on Artificial Intelligence and Statistics (AISTATS), 2024. <br>
	[<a href="https://proceedings.mlr.press/v238/chen24b/chen24b.pdf">pdf</a>]
	</li></ul>	

	<ul><li> Zhuanghua Liu, <b>Luo Luo</b>*, Bryan Kian Hsiang Low. <br>
	Incremental Quasi-Newton Methods with Faster Superlinear Convergence Rates. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2024. <br>
	[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/29319/30489">pdf</a>]	
	</li></ul>

	<ul><li> Zhenwei Lin, Jingfan Xia, Qi Deng, <b>Luo Luo</b>. <br>
	Decentralized Gradient-Free Methods for Stochastic Non-Smooth Non-Convex Optimization. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2024.  <a href="https://aaai.org/wp-content/uploads/2024/02/Update-Oral-accepts-paper-schedule-2.22.24.pdf" style="text-decoration:none"> <b> <font color="#FF0000"> Oral </font> </b> <a> <br>
	[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/29697/31193">pdf</a>]	
	</li></ul>	

	<ul><li> Haishan Ye, <b>Luo Luo</b>*, Ziang Zhou, Tong Zhang. <br>
	Multi-Consensus Decentralized Accelerated Gradient Descent. <br>
	Journal of Machine Learning Research (JMLR), 24(306):1−50, 2023. <br>
	[<a href="https://jmlr.org/papers/volume24/22-1210/22-1210.pdf">pdf</a>] 	
	</li></ul>

	<ul><li> Chengchang Liu, Cheng Chen, <b>Luo Luo</b>, John C.S. Lui. <br>
	Block Broyden's Methods for Solving Nonlinear Equations. <br>
	Conference on Neural Information Processing Systems (NeurIPS), 2023. <br>
	[<a href="https://openreview.net/pdf?id=hHv3UuffXV">pdf</a>] 	
	</li></ul>
	
	<ul><li> Chengchang Liu, Lesi Chen, <b>Luo Luo</b>*, John C.S. Lui. <br>
	Communication Efficient Distributed Newton Method with Fast Convergence Rates. <br>
	ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2023. <br>
	[<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599280">pdf</a>] 	
	</li></ul>
		
	<ul><li> Lesi Chen, Jing Xu, <b>Luo Luo</b>*. <br>
	Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic Optimization. <br>
	International Conference on Machine Learning (ICML), 2023. <br>
	[<a href="https://proceedings.mlr.press/v202/chen23ai/chen23ai.pdf">pdf</a>] 
	</li></ul>

	<ul><li> Chengchang Liu, <b> Luo Luo</b>*. <br>
	Quasi-Newton Methods for Saddle Point Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022.  <a href="https://nips.cc/virtual/2022/spotlight/65236" style="text-decoration:none"> <b> <font color="#FF0000"> Spotlight </font> </b> <a> <br>
	[<a href="https://openreview.net/pdf?id=pELM0QgWIjn">pdf</a>] [<a href="https://arxiv.org/pdf/2111.02708.pdf">Longer Version</a>]
	</li></ul>	

	<ul><li> Lesi Chen, Boyuan Yao, <b> Luo Luo</b>*. <br>
	Faster Stochastic Algorithms for Minimax Optimization under Polyak-&#321;ojasiewicz Condition. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022. <br>
	[<a href="https://openreview.net/pdf?id=JSha3zfdmSo">pdf</a>] 
	</li></ul>	
	
	<ul><li> <b>Luo Luo</b>, Yujun Li, Cheng Chen. <br>
	Finding Second-Order Stationary Points in Nonconvex-Strongly-Concave Minimax Optimization. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022. <br>
	[<a href="https://openreview.net/pdf?id=Jb-d9fZX14">pdf</a>] 
	</li></ul>		
	
	<ul><li> Chengchang Liu, Shuxian Bi, <b>Luo Luo</b>*, John C.S. Lui. <br>
	Partial-Quasi-Newton Methods: Efficient Algorithms for Minimax Optimization Problems with Unbalanced Dimensionality. <br>
	ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2022.  <a href="https://kdd.org/awards/view/2022-sigkdd-best-paper-award-winners" style="text-decoration:none"> <b> <font color="#FF0000">Best Paper Runner-Up Award </font> </b> <a> <br> 
	[<a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539379">pdf</a>] 	
	</li></ul>	
	
	<ul><li> Haishan Ye, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Approximate Newton Methods. <br>
	Journal of Machine Learning Research (JMLR), 22(66):1−41, 2021. <br>
	[<a href="https://jmlr.org/papers/volume22/19-870/19-870.pdf">pdf</a>] 
	</li></ul>

	<ul><li> <b> Luo Luo</b>, Cheng Chen, Guangzeng Xie, Haishan Ye. <br>
	Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2021. <br>
	[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17065/16872">pdf</a>] 
	</li></ul>

	<ul><li> Haishan Ye, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Nesterov's Acceleration for Approximate Newton. <br>
	Journal of Machine Learning Research (JMLR), 21(142):1−37, 2020. <br>
	[<a href="https://jmlr.org/papers/volume21/19-265/19-265.pdf">pdf</a>] 
	</li></ul>

	<ul><li> Haishan Ye, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Accelerated Proximal Sub-Sampled Newton Method. <br>
	IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020. <br>
	[<a href="https://ieeexplore.ieee.org/document/9189826">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Haishan Ye, Zhichao Huang, Tong Zhang. <br>
	Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/ecb47fbb07a752413640f82a945530f8-Paper.pdf">pdf</a>] 
	</li></ul>	

	<ul><li> Cheng Chen, <b> Luo Luo</b>*, Weinan Zhang, Yong Yu. <br>
	Efficient Projection-Free Algorithms for Saddle Point Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/7a53928fa4dd31e82c6ef826f341daec-Paper.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Haishan Ye, Ziang Zhou, <b> Luo Luo</b>, Tong Zhang. <br>
	Decentralized Accelerated Proximal Gradient Descent. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/d4b5b5c16df28e61124e13181db7774c-Paper.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Guangzeng Xie, <b> Luo Luo</b>, Yijiang Lian, Zhihua Zhang. <br>
	Lower Complexity Bounds for Finite-Sum Convex-Concave Minimax Optimization Problems. <br>
	International Conference on Machine Learning (ICML), 2020. <br>
	[<a href="http://proceedings.mlr.press/v119/xie20d/xie20d.pdf">pdf</a>]
	</li></ul>
	
	<ul><li> Cheng Chen, <b> Luo Luo</b>, Weinan Zhang, Yong Yu, Yijiang Lian. <br>
	Efficient and Robust High-Dimensional Linear Contextual Bandits. <br>
	International Joint Conference on Artificial Intelligence (IJCAI), 2020. <br>
	[<a href="https://www.ijcai.org/proceedings/2020/0588.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Cheng Chen, Zhihua Zhang, Wu-Jun Li, Tong Zhang. <br>
	Robust Frequent Directions with Application in Online Learning. <br>
	Journal of Machine Learning Research (JMLR), 20(45):1−41, 2019. <br>
	[<a href="https://www.jmlr.org/papers/volume20/17-773/17-773.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Haishan Ye, Guangzeng Xie, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Fast Stochastic Second-Order Method Logarithmic in Condition Number. <br>
	Pattern Recognition, 88:629-642, 2019.  <br>
	[<a href="https://www.sciencedirect.com/science/article/pii/S0031320318304163">pdf</a>] 
	</li></ul>

	<ul><li> <b> Luo Luo</b>, Wenpeng Zhang, Zhihua Zhang, Wenwu Zhu, Tong Zhang, Jian Pei. <br>
	Sketched Follow-The-Regularized-Leader for Online Factorization Machine. <br>
	ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2018. <br>
	[<a href="https://dl.acm.org/doi/pdf/10.1145/3219819.3220044">pdf</a>] 
	</li></ul>
	
	<ul><li> Haishan Ye, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Approximate Newton Methods and Their Local Convergence. <br>
	International Conference on Machine Learning (ICML), 2017.  <br> 
	[<a href="http://proceedings.mlr.press/v70/ye17a/ye17a.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Zihao Chen, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Communication Lower Bounds for Distributed Convex Optimization: Partition Data on Features. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2017. <a href="https://aaai.org/wp-content/uploads/2023/01/aaai17schedule.pdf" style="text-decoration:none"> <b> <font color="#FF0000"> Oral </font> </b> <a> <br>
	[<a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14846/14340">pdf</a>] 
	</li></ul>

	<ul><li> Shusen Wang, <b> Luo Luo</b>, Zhihua Zhang. <br>
	SPSD Matrix Approximation vis Column Selection: Theories, Algorithms and Extensions. <br>
	Journal of Machine Learning Research (JMLR), 17(49):1−49, 2016. <br>
	[<a href="https://www.jmlr.org/papers/volume17/14-199/14-199.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Tianfan Fu, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Quasi-Newton Hamiltonian Monte Carlo. <br>
	Conference on Uncertainty in Artificial Intelligence (UAI), 2016. <br>
	[<a href="http://auai.org/uai2016/proceedings/papers/102.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Qiaomin Ye, <b> Luo Luo</b>, Zhihua Zhang. <br>
	Frequent Direction Algorithms for Approximate Matrix Multiplication with Applications in CCA. <br>
	International Joint Conference on Artificial Intelligence (IJCAI), 2016. <br>
	[<a href="https://www.ijcai.org/Proceedings/16/Papers/328.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Yubo Xie, Zhihua Zhang, Wu-Jun Li. <br>
	Support Matrix Machines. <br>
	International Conference on Machine Learning (ICML), 2015. <br>
	[<a href="http://proceedings.mlr.press/v37/luo15.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Zhiquan Liu, <b> Luo Luo</b>, Wu-Jun Li. <br>
	Robust Crowdsourced Learning. <br>
	IEEE International Conference on Big Data, 2013. <br>
	[<a href="https://ieeexplore.ieee.org/abstract/document/6691593">pdf</a>] 
	</li></ul>
	
	<hr>	

    <script type="text/javascript">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['\\(','\\)']]
        }
    });
    </script>
</body>
</html>

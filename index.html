<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <title> Luo Luo (Fudan) </title>
   <link rel="icon" href="fudan.png" mce_href="fudan.png" type="image/x-icon">
   <link rel=stylesheet href="style.css" type="text/css">
</head>

<body>
	<h1>Luo Luo </h1>
	Assistant Professor  <br>
	School of Data Science <br>
	Fudan University <br>
	<br>
	Email: luoluo (AT) fudan (DOT) edu (DOT) cn<br>
	<br>
	My research interests include machine learning, optimization and linear algebra.
	<hr>

	<h3>Teaching </h3>
	<ul><li> Spring 2022: <a href="teaching/math620156.html"> Multivariate Statistics (MATH 620156) </a> </li></ul>
	<ul><li> Fall 2020: <a href="teaching/math1013.html"> Calculus IB (MATH 1013) </a></li></ul>
	<hr>
	
	<h3> Preprints </h3>
	
	<ul><li> Lesi Chen, Jing Xu and <b>Luo Luo</b>. <br>
	Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic Optimization. <br>
	arXiv preprint:2301.06428, 2023. <br>
	[<a href="https://arxiv.org/pdf/2301.06428.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Chengchang Liu and <b>Luo Luo</b>. <br>
	Regularized Newton Methods for Monotone Variational Inequalities with H&#246;lder Continuous Jacobians. <br>
	arXiv preprint:2212.07824, 2022. <br>
	[<a href="https://arxiv.org/pdf/2212.07824.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Lesi Chen, Haishan Ye and <b>Luo Luo</b>. <br>
	A Simple and Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization. <br>
	arXiv preprint:2212.02387, 2022. <br>
	[<a href="https://arxiv.org/pdf/2212.02387.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b> and Haishan Ye. <br>
	An Optimal Stochastic Algorithm for Decentralized Nonconvex Finite-sum Optimization. <br>
	arXiv preprint:2210.13931, 2022. <br>
	[<a href="https://arxiv.org/pdf/2210.13931.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Lesi Chen and <b> Luo Luo</b>. <br>
	Near-Optimal Algorithms for Making the Gradient Small in Stochastic Minimax Optimization. <br>
	arXiv preprint:2208.05925, 2022. <br>
	[<a href="https://arxiv.org/pdf/2208.05925.pdf">pdf</a>] 
	</li></ul>
		
	<ul><li> Haishan Ye, <b> Luo Luo</b>, Ziang Zhou and Tong Zhang. <br>
	Multi-Consensus Decentralized Accelerated Gradient Descent. <br>
	arXiv preprint:2005.00797, 2020. <br>
	[<a href="https://arxiv.org/pdf/2005.00797.pdf">pdf</a>] 
	</li></ul>
	
	<h3> Conference Publications </h3>

	<ul><li> Chengchang Liu and <b> Luo Luo</b>. <br>
	Quasi-Newton Methods for Saddle Point Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022. <br>
	[<a href="paper/NIPS2022b.pdf">pdf</a>] 
	</li></ul>	

	<ul><li> Lesi Chen, Boyuan Yao and <b> Luo Luo</b>. <br>
	Faster Stochastic Algorithms for Minimax Optimization under Polyak-&#321;ojasiewicz Condition. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022. <br>
	[<a href="paper/NIPS2022a.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> <b> Luo Luo</b>, Yujun Li and Cheng Chen. <br>
	Finding Second-Order Stationary Points in Nonconvex-Strongly-Concave Minimax Optimization. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2022. <br>
	[<a href="https://arxiv.org/pdf/2110.04814.pdf">pdf</a>] 
	</li></ul>		
	
	<ul><li> Chengchang Liu, Shuxian Bi, <b> Luo Luo</b> and John C.S. Lui. <br>
	Partial-Quasi-Newton Methods: Efficient Algorithms for Minimax Optimization Problems with Unbalanced Dimensionality. <br>
	ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2022.  <a href="https://kdd.org/awards/view/2022-sigkdd-best-paper-award-winners" style="text-decoration:none"> <b> <font color="#FF0000">Best Paper Runner-Up</font> </b> <a> <br> 
	[<a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539379">pdf</a>] 	
	</li></ul>	
	
	<ul><li> <b> Luo Luo</b>, Cheng Chen, Guangzeng Xie and Haishan Ye. <br>
	Revisiting Co-Occurring Directions: Sharper Analysis and Efficient Algorithm for Sparse Matrices. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2021. <br>
	[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17065/16872">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Haishan Ye, Zhichao Huang and Tong Zhang. <br>
	Stochastic Recursive Gradient Descent Ascent for Stochastic Nonconvex-Strongly-Concave Minimax Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/ecb47fbb07a752413640f82a945530f8-Paper.pdf">pdf</a>] 
	</li></ul>	

	<ul><li> Cheng Chen, <b> Luo Luo</b>, Weinan Zhang and Yong Yu. <br>
	Efficient Projection-Free Algorithms for Saddle Point Problems. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/7a53928fa4dd31e82c6ef826f341daec-Paper.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Haishan Ye, Ziang Zhou, <b> Luo Luo</b> and Tong Zhang. <br>
	Decentralized Accelerated Proximal Gradient Descent. <br>
	Advances in Neural Information Processing Systems (NeurIPS), 2020. <br>
	[<a href="https://papers.nips.cc/paper/2020/file/d4b5b5c16df28e61124e13181db7774c-Paper.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> Guangzeng Xie, <b> Luo Luo</b>, Yijiang Lian and Zhihua Zhang. <br>
	Lower Complexity Bounds for Finite-Sum Convex-Concave Minimax Optimization Problems. <br>
	International Conference on Machine Learning (ICML), 2020. <br>
	[<a href="http://proceedings.mlr.press/v119/xie20d/xie20d.pdf">pdf</a>]
	</li></ul>
	
	<ul><li> Cheng Chen, <b> Luo Luo</b>, Weinan Zhang, Yong Yu and Yijiang Lian. <br>
	Efficient and Robust High-Dimensional Linear Contextual Bandits. <br>
	International Joint Conference on Artificial Intelligence (IJCAI), 2020. <br>
	[<a href="https://www.ijcai.org/proceedings/2020/0588.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Wenpeng Zhang, Zhihua Zhang, Wenwu Zhu, Tong Zhang and Jian Pei. <br>
	Sketched Follow-The-Regularized-Leader for Online Factorization Machine. <br>
	ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2018. <br>
	[<a href="https://dl.acm.org/doi/pdf/10.1145/3219819.3220044">pdf</a>] 
	</li></ul>
	
	<ul><li> Haishan Ye, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Approximate Newton Methods and Their Local Convergence. <br>
	International Conference on Machine Learning (ICML), 2017. <br>
	[<a href="http://proceedings.mlr.press/v70/ye17a/ye17a.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Zihao Chen, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Communication Lower Bounds for Distributed Convex Optimization: Partition Data on Features. <br>
	AAAI Conference on Artificial Intelligence (AAAI), 2017. <br>
	[<a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14846/14340">pdf</a>] 
	</li></ul>
	
	<ul><li> Tianfan Fu, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Quasi-Newton Hamiltonian Monte Carlo. <br>
	Conference on Uncertainty in Artificial Intelligence (UAI), 2016. <br>
	[<a href="http://auai.org/uai2016/proceedings/papers/102.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Qiaomin Ye, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Frequent Direction Algorithms for Approximate Matrix Multiplication with Applications in CCA. <br>
	International Joint Conference on Artificial Intelligence (IJCAI), 2016. <br>
	[<a href="https://www.ijcai.org/Proceedings/16/Papers/328.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> <b> Luo Luo</b>, Yubo Xie, Zhihua Zhang and Wu-Jun Li. <br>
	Support Matrix Machines. <br>
	International Conference on Machine Learning (ICML), 2015. <br>
	[<a href="http://proceedings.mlr.press/v37/luo15.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Zhiquan Liu, <b> Luo Luo</b> and Wu-Jun Li. <br>
	Robust Crowdsourced Learning. <br>
	IEEE International Conference on Big Data, 2013. <br>
	[<a href="https://ieeexplore.ieee.org/abstract/document/6691593">pdf</a>] 
	</li></ul>

	<h3> Journal Publications </h3>
	
	<ul><li> Haishan Ye, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Approximate Newton Methods. <br>
	Journal of Machine Learning Research (JMLR), 22(66):1-41, 2021. <br>
	[<a href="https://jmlr.org/papers/volume22/19-870/19-870.pdf">pdf</a>] 
	</li></ul>

	<ul><li> Haishan Ye, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Accelerated Proximal Sub-Sampled Newton Method. <br>
	IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020. <br>
	[<a href="https://ieeexplore.ieee.org/document/9189826">pdf</a>] 
	</li></ul>
	
	<ul><li> Haishan Ye, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Nesterov's Acceleration for Approximate Newton. <br>
	Journal of Machine Learning Research (JMLR), 21(142):1-37, 2020. <br>
	[<a href="https://jmlr.org/papers/volume21/19-265/19-265.pdf">pdf</a>] 
	</li></ul>	
	
	<ul><li> <b> Luo Luo</b>, Cheng Chen, Zhihua Zhang, Wu-Jun Li and Tong Zhang. <br>
	Robust Frequent Directions with Application in Online Learning. <br>
	Journal of Machine Learning Research (JMLR), 20(45):1-41, 2019. <br>
	[<a href="https://www.jmlr.org/papers/volume20/17-773/17-773.pdf">pdf</a>] 
	</li></ul>
	
	<ul><li> Haishan Ye, Guangzeng Xie, <b> Luo Luo</b> and Zhihua Zhang. <br>
	Fast Stochastic Second-Order Method Logarithmic in Condition Number. <br>
	Pattern Recognition, 88:629-642, 2019.  <br>
	[<a href="https://www.sciencedirect.com/science/article/pii/S0031320318304163">pdf</a>] 
	</li></ul>	

	<ul><li> Shusen Wang, <b> Luo Luo</b> and Zhihua Zhang. <br>
	SPSD Matrix Approximation vis Column Selection: Theories, Algorithms and Extensions. <br>
	Journal of Machine Learning Research (JMLR), 17(49):1-49, 2016. <br>
	[<a href="https://www.jmlr.org/papers/volume17/14-199/14-199.pdf">pdf</a>] 
	</li></ul>	
		
	<hr>	
</body>
</html>
